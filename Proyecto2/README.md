
# <center> Proyecto 2- Tweets del Clima </center>

Este proyecto tiene como propÃ³sito aplicar los conocimientos adquiridos mediante la implementaciÃ³n de una arquitectura en Google Cloud Platform (GCP) utilizando Google Kubernetes Engine (GKE). El objetivo es construir una arquitectura de sistema distribuido genÃ©rico que muestre lostuits sobre el clima mundial. Esto se procesa mediante una arquitectura conceptual escalable. Este proyecto pretende mostrar la concurrencia de tuits en el sistema.

El proyecto consume datos meteorolÃ³gicos desde una API REST, los reenvia a una API gRPC y los almacena usando Kafka y RabbitMQ en Redis y Valkey respectivamente, todo monitoreado en Grafana y con pruebas de carga desde Locust.


## ğŸ—ï¸â€‹ Arquitectura

![Arquitectura](imgs/Arquitectura.png)

## ğŸ› ï¸ Componentes del Sistema

#### **API Rust**
- ReenvÃ­a las solicitudes a la API HTTP en Go.
- Expuesta por Ingress en `/input`.

#### **API Go HTTP**
- Recibe el JSON, lo envÃ­a por gRPC a la API gRPC.

#### **API Go gRPC**
- Publica el mensaje en **Kafka** y en **RabbitMQ**.

#### **Consumers**
- **Kafka Consumer**: almacena en Redis.
- **RabbitMQ Consumer**: almacena en Valkey.

#### **Redis y Valkey**
- Almacenamiento de mensajes por tipo de cola.

#### **Grafana**
- Dashboards para visualizar mensajes recibidos de Redis y Valkey.
- Se configurÃ³ el plugin `redis-datasource`.

![Grafana](imgs/Grafana.png)

#### **Ingress Controller**
- Gestiona el trÃ¡fico externo.
- Accesible desde: `http://<IP>.nip.io/input` y `http://<IP>.nip.io/grafana`.

##### ğŸŒ ExplicaciÃ³n del Ingress (`ingress.yaml`)

El siguiente manifiesto Ingress se encarga de **exponer al exterior dos servicios internos del clÃºster**: la **API en Rust** y la interfaz de **Grafana**, utilizando un Ãºnico dominio pÃºblico (`nip.io`).

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: weather-ingress
  namespace: ingress-nginx
  annotations:
    nginx.ingress.kubernetes.io/enable-rewrite-log: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
spec:
  ingressClassName: nginx
  rules:
    - host: 104.155.141.80.nip.io
      http:
        paths:
          - path: /input
            pathType: Prefix
            backend:
              service:
                name: api-rust-service
                port:
                  number: 8080
          - path: /grafana
            pathType: Prefix
            backend:
              service:
                name: grafana
                port:
                  number: 3000
```

##### âœ… Â¿QuÃ© hace este Ingress?

- **`kind: Ingress`**: Declara un recurso que permite enrutar trÃ¡fico HTTP externo hacia servicios internos del clÃºster.
- **`host: 104.155.141.80.nip.io`**: Define el dominio que se usarÃ¡ para acceder. Gracias a `nip.io`, no hace falta configurar DNS manualmente.
- **`paths`**:
  - `/input`: Redirige las peticiones POST hacia el servicio `api-rust-service` (puerto 8080), es decir, a la API REST que recibe los datos del clima.
  - `/grafana`: Redirige las peticiones hacia el dashboard de Grafana (puerto 3000).
- **`annotations`**:
  - `enable-rewrite-log`: Activa el logeo de reglas de reescritura para depuraciÃ³n.
  - `force-ssl-redirect: false`: Permite que las conexiones HTTP funcionen sin forzar HTTPS (ideal en entornos de prueba/local).

---

##### ğŸŒ Â¿CÃ³mo funciona en la prÃ¡ctica?

- Cuando un usuario accede a `http://104.155.141.80.nip.io/input`, NGINX redirige internamente al servicio de Rust.
- Cuando accede a `http://104.155.141.80.nip.io/grafana`, ve la interfaz de Grafana con soporte completo para subrutas gracias a las variables `GF_SERVER_ROOT_URL` y `GF_SERVER_SERVE_FROM_SUB_PATH=true`.




#### **Harbor**
- Servidor de imÃ¡genes Docker auto hospedado en una VM en GCP.

---

## â˜ï¸â€‹ Despliegue en la Nube
#### ğŸ”§ Entorno
- GCP: Google Kubernetes Engine (GKE).
- Helm: para Ingress.
- Certbot: para HTTPS en Harbor.

#### âš™ï¸ Recursos
- Cluster GKE de 3 nodos, 6 CPUs virtuales, 12 GB RAM.
- LÃ­mite de CPU y RAM configurado para cada pod.
- PV para persistencia de Grafana.

#### ğŸ“ Comandos Utilizados (Los mismos se pueden aplicar para poner en marcha el proyecto)

- Construir imagenes de docker (Estar dentro de la carpeta de api_rust y api_go respectivamente):
    
        docker build -t api_rust:latest .
        docker build -f http/Dockerfile -t api_go_http:latest .
        docker build -f grpc/Dockerfile -t api_go_grpc:latest .
        docker build -f kafka_consumer/Dockerfile -t kafka_consumer:latest .
        docker build -f rabbitmq_consumer/Dockerfile -t rabbitmq_consumer:latest .

- Tag y push a las imÃ¡genes con la respectiva IP a la VM que contiene Harbor:

        docker tag api_rust:latest 34.69.137.65.nip.io/proyecto/api_rust:latest
        docker tag api_rust:latest 34.69.137.65.nip.io/proyecto/api_go_http:latest
        docker tag api_rust:latest 34.69.137.65.nip.io/proyecto/api_go_grpc:latest
        docker tag api_rust:latest 34.69.137.65.nip.io/proyecto/kafka_consumer:latest
        docker tag api_rust:latest 34.69.137.65.nip.io/proyecto/rabbitmq_consumer:latest
        docker push 34.69.137.65.nip.io/proyecto/api_rust:latest
        docker push 34.69.137.65.nip.io/proyecto/api_go_http:latest
        docker push 34.69.137.65.nip.io/proyecto/api_go_grpc:latest
        docker push 34.69.137.65.nip.io/proyecto/kafka_consumer:latest
        docker push 34.69.137.65.nip.io/proyecto/rabbitmq_consumer:latest

- Comandos utilizados en el cluster de Kubernetes:

        helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx --create-namespace
        kubectl get pods -n ingress-nginx
        kubectl get svc -n ingress-nginx
        kubectl create -f https://strimzi.io/install/latest?namespace=ingress-nginx
        kubectl apply -f . -n ingress-nginx 
        kubectl get pods -n ingress-nginx
        kubectl get services -n ingress-nginx
---

## â€‹ğŸâ€‹ Pruebas con Locust
- URL: `http://<IP>.nip.io/input`
- Se realizaron pruebas con 100 usuarios simultÃ¡neos.
- Resultados:
  - Respuestas exitosas.
  - MÃ©tricas estables sin caÃ­das.

![Locust](imgs/Locust.png)
---

## âš™ï¸â€‹ Consideraciones TÃ©cnicas
- Uso de `os.Getenv` para parametrizaciÃ³n.
- Despliegue dividido en manifiestos `producciÃ³n`.
- Uso de `ClusterIP` para todos los servicios internos.
- Uso de `nip.io` para exponer servicios sin configurar DNS.

---

## ğŸ“„ Deployments y Preguntas


### ğŸ“¦ DescripciÃ³n de Deployments

| Componente         | Tipo          | RÃ©plicas | Namespace      | Imagen                                      |
|-------------------|---------------|----------|----------------|---------------------------------------------|
| API Rust          | Deployment    | 1        | ingress-nginx  | `api_rust`                                  |
| API Go HTTP       | Deployment    | 2        | ingress-nginx  | `api_go_http`                               |
| API Go gRPC       | Deployment    | 2        | ingress-nginx  | `api_go_grpc`                               |
| Kafka Consumer    | Deployment    | 2        | ingress-nginx  | `kafka_consumer`                            |
| RabbitMQ Consumer | Deployment    | 2        | ingress-nginx  | `rabbitmq_consumer`                         |
| Redis             | Deployment    | 2        | ingress-nginx  | `redis:7.2`                                 |
| Valkey            | Deployment    | 2        | ingress-nginx  | `valkey/valkey:7.2`                          |
| RabbitMQ          | StatefulSet   | 1        | ingress-nginx  | `rabbitmq:3-management`                     |
| Kafka             | Kafka (CRD)   | 2        | default         | Usando Strimzi Operator                     |
| Grafana           | Deployment    | 1        | ingress-nginx  | `grafana/grafana:10.2.3` (con PV persistente) |



### ğŸ“˜ Explicaciones y Preguntas

#### ğŸ“Œ Â¿CÃ³mo funciona Kafka?

Kafka es un sistema de mensajerÃ­a distribuido basado en logs. Los productores envÃ­an mensajes a "topics", que estÃ¡n divididos en particiones. Los consumidores se suscriben a estos topics y leen los mensajes en orden. Kafka es altamente escalable y tolerante a fallos, lo que lo hace ideal para manejar grandes volÃºmenes de datos en tiempo real.

**Ejemplo**:
En este proyecto, la API gRPC publica mensajes del clima en un topic llamado `message`, y un consumidor en Go los extrae y guarda en Redis.

---

#### ğŸ“Œ Â¿CÃ³mo difiere Valkey de Redis?

Valkey es un fork de Redis surgido despuÃ©s del cambio de licencia en Redis. Aunque actualmente son 100% compatibles, Valkey se centra en mantener una comunidad libre con licencia BSD y estÃ¡ empezando a agregar caracterÃ­sticas nuevas propias.

**Ejemplo**:
Ambos se usaron en el proyecto: Redis para Kafka y Valkey para RabbitMQ, sin necesidad de cambiar cÃ³digo en los consumidores gracias a la compatibilidad.

---

#### ğŸ“Œ Â¿Es mejor gRPC que HTTP?

gRPC es mÃ¡s eficiente y rÃ¡pido que HTTP en muchos contextos porque usa Protobuf (binario), lo cual reduce el tamaÃ±o de los mensajes y mejora la latencia. TambiÃ©n permite comunicaciÃ³n bidireccional, streaming y definiciÃ³n de contratos estrictos (con .proto).

Sin embargo, HTTP es mÃ¡s simple, universal y fÃ¡cil de consumir desde clientes web o herramientas como Postman.

**En este proyecto**:
- HTTP se usÃ³ para la API REST expuesta.
- gRPC se usÃ³ internamente para la lÃ³gica distribuida entre servicios.

---

#### ğŸ“Œ Â¿Hubo una mejora al utilizar dos rÃ©plicas en los deployments de API REST y gRPC? Justifique su respuesta.

âœ… SÃ­, hubo una mejora notable en:
- **Disponibilidad**: Si una rÃ©plica falla, la otra sigue funcionando.
- **Balanceo de carga**: El Ingress y Kubernetes distribuyen las peticiones entre las rÃ©plicas.
- **Escalabilidad**: Con Locust se logrÃ³ mantener rendimiento estable con mÃºltiples usuarios concurrentes.

---

#### ğŸ“Œ Para los consumidores, Â¿QuÃ© utilizÃ³ y por quÃ©?

Se utilizÃ³:

- **Go** como lenguaje de los consumidores.
- **Redis (para Kafka)**: Por eficiencia y compatibilidad con `segmentio/kafka-go`.
- **Valkey (para RabbitMQ)**: Como soluciÃ³n equivalente libre, compatible con Redis.

Esto permite visualizar mÃ©tricas en Grafana desde ambas fuentes, diferenciando quÃ© sistema de mensajerÃ­a fue utilizado.

---